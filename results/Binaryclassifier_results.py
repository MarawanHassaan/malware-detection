Python 3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)] on win32
Type "help", "copyright", "credits" or "license()" for more information.
>>> 
= RESTART: C:\Users\maraw\OneDrive\Desktop\ML homework 1\Binaryclassifier.py =
Opening the file ...
Preparing the dataset ...
(24152,)
(24152,)
(24152, 80888)
(24152,)
logr_features_weights

Warning (from warnings module):
  File "C:\Users\maraw\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\linear_model\logistic.py", line 432
    FutureWarning)
FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.

Warning (from warnings module):
  File "C:\Users\maraw\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\svm\base.py", line 929
    "the number of iterations.", ConvergenceWarning)
ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
(24152, 11507)
Random element selection is chosen at 53 
Train: 19321 - Test: 4831
LinearSVC model created
[[1888  435]
 [ 220 2288]]
              precision    recall  f1-score   support

           H       0.90      0.81      0.85      2323
           L       0.84      0.91      0.87      2508

    accuracy                           0.86      4831
   macro avg       0.87      0.86      0.86      4831
weighted avg       0.87      0.86      0.86      4831

0.8644173049058166
Logistic Regression model created
[[1842  481]
 [ 435 2073]]
              precision    recall  f1-score   support

           H       0.81      0.79      0.80      2323
           L       0.81      0.83      0.82      2508

    accuracy                           0.81      4831
   macro avg       0.81      0.81      0.81      4831
weighted avg       0.81      0.81      0.81      4831

0.8103912233492031
Multinomial Naive Bayes model created
[[2085  238]
 [ 706 1802]]
              precision    recall  f1-score   support

           H       0.75      0.90      0.82      2323
           L       0.88      0.72      0.79      2508

    accuracy                           0.80      4831
   macro avg       0.82      0.81      0.80      4831
weighted avg       0.82      0.80      0.80      4831

0.8045953218795281
Decision Tree created
[[1941  382]
 [ 300 2208]]
              precision    recall  f1-score   support

           H       0.87      0.84      0.85      2323
           L       0.85      0.88      0.87      2508

    accuracy                           0.86      4831
   macro avg       0.86      0.86      0.86      4831
weighted avg       0.86      0.86      0.86      4831

0.8588283999172014
Random Forest created
[[2149  174]
 [ 283 2225]]
              precision    recall  f1-score   support

           H       0.88      0.93      0.90      2323
           L       0.93      0.89      0.91      2508

    accuracy                           0.91      4831
   macro avg       0.91      0.91      0.91      4831
weighted avg       0.91      0.91      0.91      4831

0.9054026081556613
svm_features_weights

Warning (from warnings module):
  File "C:\Users\maraw\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\svm\base.py", line 929
    "the number of iterations.", ConvergenceWarning)
ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
(24152, 15231)
Random element selection is chosen at 4768 
Train: 19321 - Test: 4831
LinearSVC model created
[[2000  323]
 [ 247 2261]]
              precision    recall  f1-score   support

           H       0.89      0.86      0.88      2323
           L       0.88      0.90      0.89      2508

    accuracy                           0.88      4831
   macro avg       0.88      0.88      0.88      4831
weighted avg       0.88      0.88      0.88      4831

0.8820120057959014

Warning (from warnings module):
  File "C:\Users\maraw\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\linear_model\logistic.py", line 432
    FutureWarning)
FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
Logistic Regression model created
[[1827  496]
 [ 418 2090]]
              precision    recall  f1-score   support

           H       0.81      0.79      0.80      2323
           L       0.81      0.83      0.82      2508

    accuracy                           0.81      4831
   macro avg       0.81      0.81      0.81      4831
weighted avg       0.81      0.81      0.81      4831

0.8108052163113227
Multinomial Naive Bayes model created
[[2098  225]
 [ 723 1785]]
              precision    recall  f1-score   support

           H       0.74      0.90      0.82      2323
           L       0.89      0.71      0.79      2508

    accuracy                           0.80      4831
   macro avg       0.82      0.81      0.80      4831
weighted avg       0.82      0.80      0.80      4831

0.8037673359552887
Decision Tree created
[[1945  378]
 [ 308 2200]]
              precision    recall  f1-score   support

           H       0.86      0.84      0.85      2323
           L       0.85      0.88      0.87      2508

    accuracy                           0.86      4831
   macro avg       0.86      0.86      0.86      4831
weighted avg       0.86      0.86      0.86      4831

0.8580004139929621
Random Forest created
[[2138  185]
 [ 277 2231]]
              precision    recall  f1-score   support

           H       0.89      0.92      0.90      2323
           L       0.92      0.89      0.91      2508

    accuracy                           0.90      4831
   macro avg       0.90      0.90      0.90      4831
weighted avg       0.91      0.90      0.90      4831

0.9043676257503622
>>> 
