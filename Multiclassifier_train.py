##########################################################Imports#####################################################################################
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import *
from sklearn.naive_bayes import *
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn import tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel


##########################################################Needed Functions############################################################################

#Linear SVM training
def train_linear_SVC(X_train, X_test, y_train, y_test):
    model = LinearSVC(loss='hinge').fit(X_train,y_train)
    print('LinearSVC model created')
    y_pred = model.predict(X_test)
    print(confusion_matrix(y_test, y_pred)) #y_test is the actual or the true data values
    print(classification_report(y_test, y_pred))
    print(accuracy_score(y_test,y_pred))
    return;


#Logistic Regression training
def train_logistic_regression(X_train, X_test, y_train, y_test):
    model = LogisticRegression(solver='lbfgs',multi_class='multinomial').fit(X_train, y_train)
    print('Logistic Regression model created')
    y_pred = model.predict(X_test)
    print(confusion_matrix(y_test, y_pred)) #y_test is the actual or the true data values
    print(classification_report(y_test, y_pred))
    print(accuracy_score(y_test,y_pred))
    return;

#Multinomial Naive Bayes training
def train_multinomialNB(X_train, X_test, y_train, y_test):
    model = MultinomialNB().fit(X_train, y_train)
    print('Multinomial Naive Bayes model created')
    y_pred = model.predict(X_test)
    print(confusion_matrix(y_test, y_pred)) #y_test is the actual or the true data values
    print(classification_report(y_test, y_pred))
    print(accuracy_score(y_test,y_pred))
    return;

#Decision Tree training
def train_decision_tree(X_train, X_test, y_train, y_test):
    model = tree.DecisionTreeClassifier().fit(X_train, y_train)
    print('Decision Tree created')
    y_pred = model.predict(X_test)
    print(confusion_matrix(y_test, y_pred)) #y_test is the actual or the true data values
    print(classification_report(y_test, y_pred))
    print(accuracy_score(y_test,y_pred))
    return;

#Random Forest training
def train_random_forest(X_train, X_test, y_train, y_test):
    model = RandomForestClassifier(n_estimators=100,random_state=0).fit(X_train, y_train)
    print('Random Forest created')
    y_pred = model.predict(X_test)
    print(confusion_matrix(y_test, y_pred)) #y_test is the actual or the true data values
    print(classification_report(y_test, y_pred))
    print(accuracy_score(y_test,y_pred))
    return;


#Logistic Regression Feature Selection
def logr_features_weights(X_all, y_all):
    logr = LogisticRegression().fit(X_all, y_all)
    model = SelectFromModel(logr, prefit=True)
    new_features_vectors = model.transform(X_all)
    return new_features_vectors

#LinearSVC Feature Selection
def svm_features_weights(X_all,y_all):
    lsvc = LinearSVC(loss='hinge').fit(X_all, y_all)
    model = SelectFromModel(lsvc, prefit=True)
    new_features_vectors = model.transform(X_all)
    return new_features_vectors
