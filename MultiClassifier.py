##########################################################Imports#####################################################################################
import numpy as np
import json_lines
import pandas as pd
import random
from Multiclassifier_train import *

instructions=[]
labels=[]



####################################################Preparing the dataset###############################################################################
print("Opening the file ...")
with open('train_dataset.jsonl', 'rb') as f: # opening file in binary(rb) mode

   print("Preparing the dataset ...") 
   for item in json_lines.reader(f): #We move on each line sequentially.
       inst=item['instructions'] #inst will point to the array of assembly instructions
       label=item['compiler'] #label captures the optimization value high or low
       #Since the number of low in the dataset is greater than than of the high I am only taking the first ones that make the dataset balanced
       labels.append(label)
       list_inst=[]
       for each_inst in inst: #each_inst will point to one element in the list of instructions as "push r12", "push rbp", "push rbx",
          list_inst.append(each_inst.split(' ',1)[0]) #Split the string after each 'space' and consider only the mnemonic part which is the first one aka [0]
          to_be_added=' '.join(list_inst) #Add each to the list to_be_added as a part of a string
       instructions.append(to_be_added) #instructions[0] will be {push push push test mov mov mov call ........}



####################################################Extracting the features#############################################################################
#For the lists to be passed to Sklearn, they need to be converted to numpy arrays    
instructions = np.array(instructions) 
labels = np.array(labels)

#Building the feature vector using counter vectorizer method with n-grams starting from 1 and up to 3
#Tfid basically works the same as any vectorizer however it increases the 
#importance to the newly found unique words in each line which is usefull for compiler recognition
vectorizer = TfidfVectorizer(ngram_range=(1, 3))
#vectorizer = TfidfVectorizer(ngram_range=(1, 5))
   
X_all = vectorizer.fit_transform(instructions)
y_all = labels

print(X_all.shape)
print(y_all.shape)

####################################################Feature Selection and Model creation################################################################


features_selection = [logr_features_weights, svm_features_weights]
for reduce_features in features_selection:
    print(reduce_features.__name__)
    new_features_vectors = reduce_features(X_all,y_all) #New matrix is obtained containing the most important features
    print(new_features_vectors.shape)
    X_train, X_test, y_train, y_test = train_test_split(new_features_vectors, y_all,test_size=0.2, random_state=15)
    id = random.randrange(0,X_train.shape[0])
    print('Random element is selection at random is %d ' %(id))
    print("Train: %d - Test: %d" %(X_train.shape[0],X_test.shape[0]))
    train_logistic_regression(X_train, X_test, y_train, y_test)
    train_decision_tree(X_train, X_test, y_train, y_test)
    train_random_forest(X_train, X_test, y_train, y_test)
    train_multinomialNB(X_train, X_test, y_train, y_test)
    train_linear_SVC(X_train, X_test, y_train, y_test)

